{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apache Spark: распределенное исполнение\n",
    "\n",
    "![alt text](static/spark_components.JPG \"components\")\n",
    "\n",
    "Высокоуровнево Spark приложение состоит из программы-драйвера (\"driver\") \n",
    "ответственной за \"оркестрацию\" параллельных операций на кластера. Драйвер имеет доступ к распределенным компонентам кластера, таким как Spark Executors и cluster manager, через SparkSession. \n",
    "\n",
    "<p><b>Spark Driver</b></p>\n",
    "Отвественен за поднятие SparkSession. Драйвер взаимодействует с кластер менеджером, запрашивая вычислительные ресурсы для исполнителей, трансформирует Spark операции в DAG вычисления, планирует их, распределяет задачи (Task) по всем исполнителям. Как только ресурсы выделены, общается напрямую с исполнителями\n",
    "\n",
    "<p><b>Spark Session</b></p>\n",
    "<p>С версии 2.0 стал единой точкой доступа к всей функциональности спарка, задаем параметры запуска JVM, доступ к метаданным каталога, определение DataFrame и прочее.\n</p>",
    "\n",
    "### Распределенные данные и партиции\n",
    "\n",
    "![alt text](static/logical_model.JPG \"model\")\n",
    "\n",
    "<p>Данные распределены по хранилищу в виде партиций, живущих в HDFS или облачном хранилище. В то время как данные распределены по физическому кластеру, Спарк обращается с каждой партицией как с выскоуровневой абстракцией (DataFrame в памяти). Каждый исполнитель предпочтительно выделяет задачу, требующую чтения ближайшей партиции.</p>\n",
    "\n",
    "![alt text](static/exec_partitions.JPG \"exec_part\")\n",
    "\n",
    "Разбиение (\"партиционирование\") позволяет обрабатывать задачи параллельно. Распределенная схема разбиения данных в блоки делает возможным обработку исполнителем ближайшей части, минимизируя нагрузку на сеть. Каждое ядро исполнителя ответственно за работу над одной партицией\n",
    "\n",
    "### Spark application: основные понятия\n",
    "\n",
    "![alt text](static/job.JPG \"job\")\n",
    "\n",
    "Во время интерактивный сессии, драйвер преобразует спарк приложение в одну или несколько заданий (job). Затем каждое задание трансформируется в DAG. В сущности, это один план выполнения, где каждый узел (node) внутри DAG может состоять из одного или более этапов (stages).\n",
    "\n",
    "![alt text](static/stages.JPG \"stages\")\n",
    "\n",
    "Как часть узла, этапы образуются по принципу разделения операций на последовательные и параллельные. Часто этапы делятся по границам операторов, предполагающих передачу данных среди исполнителей.\n",
    "\n",
    "![alt text](static/tasks.JPG \"tasks\")\n",
    "\n",
    "Каждый этап состоит из задач (tasks), единиц исполнения, которые затем объединяются по исполнителям. Каждой задаче ставится в соответствие одно ядро, которое работает над одной партицией.\n",
    "\n",
    "### Преобразования, действия и ленивые вычисления\n",
    "\n",
    "Операции в спарке делятся на преобразования (transformations) и действия (actions). Преобразования преобразуют DataFrame в новый DataFrame без изменения исходных данных, гарантируя свойство неизменности. Например, операции select() или filter() не меняют исходный набор данных, а вместо этого возвращает преобразованный результат в виде нового DataFrame.\n",
    "\n",
    "Все трансформации выолняются лениво, т.е результат не выполняется немедленно, а запоминается последовательность действий в виде \"lineage\". Записанная цепочка ,позже, позволяет спарку ,на этапе планирования, изменить определенные преобразования (комбинируя их различным образом, меняя порядок исполнения) для наиболее эффективного плана.\n",
    "\n",
    "![alt text](static/lazy.JPG \"lazy\")\n",
    "\n",
    "Стратегия ленивого исполнения откладывает вычисление до \"пинка\", операции действия (например, запись или чтение с диска). Действие затронет всю цепочку преобразований до своего появления. Важное свойств, устойчивость к отказу, записывая всю цепочку преобразований и гарантируя неизменность наборов данных, несложно восстановить потеренные вычисления\n",
    "\n",
    "![alt text](static/tr_act.JPG \"transform_action\")\n",
    "\n",
    "### Узкие и широкие преобразования\n",
    "\n",
    "Узкие преобразования - любые преобразования, в которых одна выходная партиция может быть вычислена из одной входной. Например, filter() или contains(), они не требуют обмена данными. В то время как groupBy() или orderBy() являются примерами широких преобразований, данные из разных партиций считываются, объединяются и записываются на диск. Подсчет count() после groupBy() требует перетасовки данных от каждой партиции исполнителей во всем кластере.\n",
    "\n",
    "![alt text](static/nar_wide.JPG \"narrow_wide\")\n",
    "\n",
    "### DataFrame vs Dataset \n",
    "\n",
    "Концептуально, можно думать о DataFrame как о коллекции обобщенных объектов, Dataset[Row], где Row это generic нетипизированный JVM объект, способный содержать поля различных типов. Dataset ,напротив, коллекция строготипизированных типов (например, создаем класс и теперь Dataset хранит в себе объекты одного типа). Различие в том, что в DF мы использовали DSL операции, не зависящие от используемого языка, в то время как в DS можем использовать родные выражения Scala и Java.\n",
    "\n",
    "<ul>\n",
    "    <li>Когда хотим описать, что достать, а не как [DS, DF]</li>\n",
    "    <li>Если хотим защищенность типов (compile type safety) берем DS</li>\n",
    "    <li>Если хотим получить выигрыш от Tungsten сериализаторы [DS]</li>\n",
    "    <li>Хотим унификации, простоты и оптимизации берем DF</li>\n",
    "    <li>Обращаемся к RDD, в случае, когда мы знаем лучше</li>\n",
    "</ul>\n",
    "\n",
    "### Spark SQL и его движок\n",
    "\n",
    "![alt text](static/spark_sql.JPG \"spark_sql\")\n",
    "\n",
    "Задачи Spark Engine:\n",
    "<ul>\n",
    "    <li>Унификация компонентов и предоставляет абстракции DF и DS</li>\n",
    "    <li>Соединение с Apache Hive</li>\n",
    "    <li>Предоставление Spark SQL Shell для исследования данных</li>\n",
    "    <li>Доступ к внешним СУБД через коннекторы</li>\n",
    "    <li>Генерация оптимизированного плана запроса и кода для JVM</li>\n",
    "</ul>\n",
    "\n",
    "### Оптимизатор Catalyst\n",
    "\n",
    "![alt text](static/catalyst.JPG \"catalyst\")\n",
    "\n",
    "Catalyst представлен 4 фазами (Анализа, Логической оптимизации, Физического планнирования и генерации кода)\n",
    "\n",
    "![alt text](static/catalyst_parsed.JPG \"catalyst_parsed\")\n",
    "\n",
    "<p><b>Анализ</b> - на стадии анализа генерируется Абстрактное Синтаксическое дерево для SQL запроса. Обращаемся к каталогу для проверки колонок и названия таблички, в случае успеха идем на следующий этап</p>\n",
    "\n",
    "<p><b>Логическая оптимизация</b> - состоит из двух этапов, на начальном этапе применяем оптимизацию на основе правил, так Catalyst построит множество планов на основе стоимостной оптимизации (Cost-based optimization) выберет лучший (по умполчанию CBO отключен). На этом этапе делаем predicate pushdown, projection prunning</p>\n",
    "\n",
    "<p><b>Физическое планирование</b> - из оптимального логического на основе стратегий создаем физический план</p>\n",
    "\n",
    "<p><b>Генерация кода</b> - на основе ФП, а именно физических операторов, с помощью проекта Tungsten и его замечательного кодогенератора (WholeStageCodeGen) создаем компактный RDD код</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
