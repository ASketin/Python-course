{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Apache Spark: управление памятью</h3>\n",
    "\n",
    "<img src=\"static/hierarchy.JPG\" alt=\"hierarchy\" width=\"500\"/>\n",
    "\n",
    "Есть несколько уровней управления памятью (Spark, Yarn, JVM, ОС). При запуске Spark приложения выделяется память для драйвера, представлена JVM, и память под исполнителей (внутреннее управление Spark-а). YARN выделяет контейнеры под исполнение для работы на различных узловых машинах (node).\n",
    "\n",
    "<img src=\"static/node_mng.JPG\" alt=\"node_mng\" width=\"500\"/>\n",
    "\n",
    "ResourceManager работает с запросами памяти, выделяя исполнителям памяти вплоть до некоторой границы, заданной yarn.scheduler.maximum-allocation-mb. Запросить больше не получится. На одной ноде, эта работа будет сделана NodeManager-ом, ресурсы которого ограничены физически, в YARN соответствующая настройка yarn.nodemanager.resource.memory-mb (физический объем памяти на NodeManager в Mb, который может быть ведлене под yarn контейнер). Один ExecutorContainer предствален JVM, вся памяти которой поделена на три секции\n",
    "\n",
    "<ul>\n",
    "    <li><b>Heap memory</b> Память задается свойством spark.executor.memory и определяет максимальную память JVM heap memory.</li>\n",
    "    <li><b>Off-Heap memory</b> Отличается от предыдущей отсутсвием сборщика мусора</li>\n",
    "<li><b>Overhead memory</b></li> экстраресурсы для особенно тяжелых задач\n",
    "</ul>\n",
    "\n",
    "Спарк предоставляет единый интерфейс управления памятью через UnifiedMemoryManager.\n",
    "\n",
    "<img src=\"static/memory_parts.JPG\" alt=\"memory_parts\" width=\"500\"/>\n",
    "\n",
    "<h4><b>Зарезервированная память</b></h4>\n",
    "\n",
    "Спарк преберегает память для хранения внутренних объектов. Это гарантирует наличие ресурсов даже для маленькой JVM heap. Устанавливается объемом 300 Мб\n",
    "\n",
    "<h4><b>Storage memory</b></h4>\n",
    "\n",
    "Нужна для кеширования и broadcast операций. Объем определяется \n",
    "$Storage Memory = usableMemory * spark.memory.fraction * spark.memory.storageFraction$\n",
    "По умолчанию занимает треть всей памяти\n",
    "\n",
    "<h4><b>Execution memory</b></h4>\n",
    "\n",
    "Память под хранение временных данных операций join, shuffle, sort и другие.\n",
    "$Execution Memory = usableMemory * spark.memory.fraction * (1 - spark.memory.storageFraction)$\n",
    "\n",
    "<h4><b>User memory</b></h4>\n",
    "\n",
    "Обычно использзуется для хранения родословни нашего DF. Имеющееся пространство можно использзовать на усмотрение пользователя.\n",
    "$User Memory = usableMemory * (1 - spark.memory.fraction)$\n",
    "\n",
    "<h4><b>Dynamic occupancy mechanism</b></h4>\n",
    "\n",
    "<img src=\"static/dynamic_occup.JPG\" alt=\"dynamic_occup\" width=\"500\"/>\n",
    "\n",
    "Общая память делится на память хранения и память исполнения. Общая память хранения может наполняться до порога onHeapStorageRegionSize, эта часть памяти используется, если она свободна от файлов исполнения. В противном случае хранение ждет освобождение ресурсов от данных исполнения. По умолчанию граница устанавливается на весь объем общей памяти.\n",
    "\n",
    "Данные исполнения имеют приоритет над хранением и последним придется уйти, особождая ресурсы. В случае заполнения заданных в настройках пропорций, в ход идет алгоритм LRU.\n",
    "\n",
    "### Оптимизация\n",
    "\n",
    "<h4><b>Виды партиций</b></h4>\n",
    "\n",
    "<ul>\n",
    "    <li><b>Входные</b> Можем управлять размером spark.sql.files.MaxPartitionBytes, обычно довольствуемся стандартными 128MB</li>\n",
    "    <li><b>Shuffle</b> Управляем количеством, ззадем spark.sql.shuffle.partitions</li>\n",
    "<li><b>Выходые</b></li> задаем количество coalesce, repartition, option(\"maxRecordesPerFile\")\n",
    "</ul>\n",
    "\n",
    "<h4><b>Persistence/Broadcast</b></h4>\n",
    "\n",
    "<img src=\"static/persist.JPG\" alt=\"persist\" width=\"500\"/>\n",
    "<img src=\"static/broadcast.JPG\" alt=\"broacast\" width=\"500\"/>\n",
    "\n",
    "<h4><b>Rules</b></h4>\n",
    "\n",
    "<img src=\"static/plan.JPG\" alt=\"broacast\" width=\"500\"/>\n",
    "\n",
    "Каждый оператор физического плана определяется выходными партициями (outputPartitioning), выходным порядком (outputOrdering), requiredChildDistribution (требование на выходные партиции дочернего оператора), requiredChildOrdering. Если требования между операторами не согласуются, вызывается перетасовка или сортировка\n",
    "\n",
    "<img src=\"static/req_1.JPG\" alt=\"req_1\" width=\"500\"/>\n",
    "<img src=\"static/req_2.JPG\" alt=\"req_2\" width=\"500\"/>\n",
    "\n",
    "Можно опустить дорогую операцию обмена и сортировки перед SMJ, проведя предварительно repartition() и сортировку внутри партиций. Выигрыш будет получен, если последующие операции не сокращают количество значений поля, по которому было проведено переразбиение.\n",
    "\n",
    "<img src=\"static/avoid_shuffle.JPG\" alt=\"avoid_shuffle\" width=\"500\"/>\n",
    "\n",
    "Глобально можно поделить техники оптимизации на переиспользование обмена (нельзя управлять напрямую, определяется оптимизатором), переиспользование вычислений (кеширование и удержание наборов данных), оптимизация способов разбиения на блоки"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
